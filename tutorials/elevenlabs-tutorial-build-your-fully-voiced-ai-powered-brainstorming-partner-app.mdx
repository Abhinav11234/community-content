---
title: "ElevenLabs Tutorial: Build Your Fully Voiced AI-Powered Brainstorming Partner App"
description: "How to utilize ElevenLabs API along with Anthropic's Claude model to build fully-voiced brainstorming partner app, built with Flask and ReactJS"
authorUsername: "septiannugraha"
---

## Introduction

In this tutorial, we will explore how to build a chatbot application using the ElevenLabs API, Anthropic's Claude, ReactJS, and Flask. We will walk through each step, from setting up the backend server to creating the frontend interface. By the end of this tutorial, you will have a fully functional, brainstorming partner chatbot that can interact with users and respond with synthesized speech.

### Introduction to ElevenLabs

ElevenLabs is a cutting-edge technology company that specializes in machine learning and artificial intelligence. Their API provides a wide range of capabilities, including speech synthesis, voice cloning, and more. In this tutorial, we will use the ElevenLabs API to generate synthesized speech for our chatbot, giving it a unique and engaging voice.

### Introduction to Anthropic's Claude

Anthropic is a research organization focused on making AI systems more understandable, controllable, and beneficial. One of their products, Claude, is a conversational AI model that can generate human-like text based on the input it receives. We will use Claude to power the conversational abilities of our chatbot, allowing it to respond to user inputs in a natural and engaging way.

### Introduction to ReactJS

ReactJS is a popular JavaScript library for building user interfaces, particularly for single-page applications. It allows developers to create large web applications that can update and render efficiently without requiring a page reload. In this tutorial, we will use ReactJS to build the frontend of our chatbot application, creating a dynamic and interactive user interface.

### Introduction to Flask

Flask is a lightweight web framework for Python. It's easy to use and perfect for building small to medium-sized web applications. In this tutorial, we will use Flask to build the backend of our chatbot application. The Flask server will handle requests from the frontend, process them using the ElevenLabs API and Anthropic's Claude, and send back responses to the frontend.

By combining these technologies, we will create a chatbot that not only can carry on a conversation with users but also respond with synthesized speech, creating a more engaging and interactive user experience. Let's get started!

### Prerequisites

- Basic knowledge of Python and preferably Flask
- Basic knowledge of Typescript and ReactJS
- Access to ElevenLabs API
- Access to Anthropic's Claude API

### Outline

1. Initializing the Projects
2. Building the Backend
3. Testing the Backend
4. Building the Frontend
5. Testing the Brainstormy App

## Discussion

In this section, we will delve into the process of building our chatbot application. We will start by initializing our projects, then move on to building and testing the backend and frontend. Finally, we will test the complete chatbot application.

### Initializing the Projects

The first step in our journey is to initialize our projects. We will be creating two separate projects: one for the backend and one for the frontend. The backend will be a Flask application, and the frontend will be a ReactJS application. We will use the `create-react-app` command to initialize our ReactJS application and manually set up our Flask application. Once our projects are initialized, we can start building the backend.

#### Backend

The backend of our application will be built using Flask, a lightweight and flexible Python web framework. To initialize our Flask application, we'll first need to set up a new Python environment. This can be done using virtualenv, a tool for creating isolated Python environments. Here's how you can do it:

1. **Create a new directory for your project:**

```bash
mkdir brainstormy-backend
cd brainstormy-backend
```

2. **Create a new virtual environment:**

```bash
python3 -m venv env
```

3. **Activate the virtual environment:**

On macOS and Linux:

```bash
source env/bin/activate
```

On Windows:

```bash
.\env\Scripts\activate
```

4. **Install Flask:**

With the virtual environment activated, you can now install Flask:

```bash
pip install flask
```

5. **Create a new Flask application:**

Create a new file named `app.py` in your project directory and open it in your text editor. Then, add the following code to create a new Flask application:

```python
from flask import Flask

app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

if __name__ == '__main__':
    app.run(debug=True)
```

This code creates a new Flask application and defines a single route that returns the text "Hello, World!".

With these steps, your Flask application is now set up and ready to be developed. In the next sections, we will add more functionality to our Flask application to communicate with the ElevenLabs API and Anthropic's Claude.

#### Frontend

The frontend of our application will be built using ReactJS, a popular JavaScript library for building user interfaces. We'll use `create-react-app`, a tool that sets up a modern web app by running one command. Here's how you can do it:

1. **Install Node.js and npm:**

Before you can use `create-react-app`, you need to have Node.js and npm (Node Package Manager) installed on your computer. You can download Node.js from the [official website](https://nodejs.org/). npm is included with Node.js.

2. **Create a new ReactJS application:**

Once Node.js and npm are installed, you can create a new ReactJS application using `create-react-app`. Open a new terminal window, navigate to the directory where you want to create your project, and run the following command:

```bash
npx create-react-app brainstormy-client --template typescript
```

This command creates a new directory named `brainstormy-client` and sets up a new ReactJS application inside it.

3. **Installing TailwindCSS for Styling**

Next, let's change directory into our `brainstormy-client` project. Once our current working directory is inside the project directory, run this command to install `tailwindcss` via npm as well as initialize the library by generating `tailwind.config.js` file.

```bash
npm install -D tailwindcss
npx tailwindcss init
```
After the `tailwind.config.js` is generated, we need to configure the template path according to the path used by `create-react-app` application.

```diff
# tailwind.config.js
/** @type {import('tailwindcss').Config} */
module.exports = {
--  content: [],
++   content: [
++     "./src/**/*.{js,jsx,ts,tsx}",
++   ],
  theme: {
    extend: {},
  },
  plugins: [],
}
```
Finally, we add the `@tailwind` directives for each of Tailwind's layers to our `./src/index.css` file.

```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

4. **Start the ReactJS application:**

Navigate into your new project directory and start the application:

```bash
cd brainstormy-client
npm start
```

This command starts the development server and opens the application in your web browser. You should see a default welcome page.

With these steps, your ReactJS application is now set up and ready to be developed. In the next sections, we will add more functionality to our ReactJS application to communicate with our Flask backend and display the chat interface.

### Building the Backend

Our backend will be responsible for communicating with the ElevenLabs API and Anthropic's Claude. We will create a Flask route that accepts POST requests with a message from the user. This message will be sent to Claude, which will generate a response. The response will then be sent to the ElevenLabs API to generate synthesized speech. The audio file will be sent back to the frontend as the response to the POST request.

Without further ado, let's install the necessary dependencies and begin editing our `app.py` file!

#### Installing the Necessary Libraries

Let's run this command to install all the required libraries in a single command

```bash
pip install flask-cors anthropic elevenlabs
pip install "pydantic==1.*"
```
This time, we also install `pydantic` library, but with the version locked to 1.*. This is necessary because the `elevenlabs` returned Pydantic-related error when using the default `pydantic` installation.

#### Editing the `app.py` file

1. **Import necessary modules and packages:**

```python
import os
from flask import request, jsonify, Response, Flask
from elevenlabs import clone, generate, play, set_api_key
import anthropic
from flask_cors import CORS
```

This section imports all the necessary modules and packages that your application will use. `os` is a standard Python library for interacting with the operating system. `flask` is the web framework you're using. `elevenlabs` and `anthropic` are the APIs for speech synthesis and conversational AI, respectively. `flask_cors` is a Flask extension for handling Cross Origin Resource Sharing (CORS), making cross-origin AJAX possible.

2. **Initialize Flask application and set up CORS:**

```python
app = Flask(__name__)
CORS(app, origins=["http://localhost:3000", "http://example.com"])
```

Here, you're initializing your Flask application and setting up CORS. This allows your frontend application (running on `http://localhost:3000` or `http://example.com`) to make requests to your Flask backend.

3. **Set API key for ElevenLabs:**

```python
set_api_key(os.getenv("XI_API_KEY"))
```

This line sets the API key for ElevenLabs, which is retrieved from the environment variables.

4. **Define route for generating chat response:**

```python
@app.route('/chat', methods=['POST'])
def generate_chat_response():
    data = request.get_json()  # Get the JSON data from request
    messages = data.get('messages', [])
    prompts = ""
    for message in messages:
        if message['role'] == 'human':
            prompts += f"{anthropic.HUMAN_PROMPT} {message['content']}"
        elif message['role'] == 'assistant':
            prompts += f"{anthropic.AI_PROMPT} {message['content']}"

    prompt = (f"{anthropic.HUMAN_PROMPT} You are my brainstorming partner. I need your help to collaboratively brainstorm some ideas and provide some suggestions according to your best ability. Please try to keep the response concise, as I'll ask follow up questions afterwards"
        f"{anthropic.AI_PROMPT} Understood, I will assist you in brainstorming some ideas together. "
        f"{prompts}")

    c = anthropic.Anthropic(api_key=os.getenv("CLAUDE_KEY"))
    resp = c.completions.create(
        prompt=f"{prompt} {anthropic.AI_PROMPT}",
        stop_sequences=[anthropic.HUMAN_PROMPT],
        model="claude-v1.3-100k",
        max_tokens_to_sample=1500,
    )

    print(resp)

    return jsonify({"status": "success", "result": resp.completion})
```

This section defines a route `/chat` that accepts POST requests. It gets the JSON data from the request, formats the prompts, and sends them to the Claude model to generate a response. The response is then returned as JSON.

5. **Define route for generating speech:**

```python
@app.route('/talk', methods=['POST'])
def generate_speech():
        data = request.get_json()
    message = data.get('message', 'No message provided')

    audio = generate(
        text=message,
        voice="Bella",
        model='eleven_monolingual_v1'
    )

    return Response(audio, mimetype='audio/mpeg')
```

This section defines a route `/talk` that also accepts POST requests. It gets the message from the request data and sends it to the ElevenLabs API to generate speech. In this tutorial, we use "Bella" voice which is readily available, pre-made voice provided by ElevenLabs API. The speech (an audio file) is then returned as a response with the MIME type `audio/mpeg`.


6. **Run the Flask application:**

```python
if __name__ == '__main__':
    app.run(debug=True)
```

Finally, this section runs the Flask application if the script is run directly (i.e., not imported as a module). The `debug=True` argument enables debug mode, providing more detailed error messages if something goes wrong.

### Testing the Backend

Before moving on to the frontend, it's crucial to ensure our backend is functioning as expected. We will use tools like Postman or Insomnia to send POST requests to our Flask routes and verify the responses. We should receive an audio file that plays the synthesized speech of Claude's response. Once we're confident that our backend is operating correctly, we can proceed to build the frontend.

To begin, ensure that your current working directory is set inside the backend project, `brainstormy-backend`. Also, confirm that your virtual environment is activated. Once all systems are ready, let's run the command to start our backend!

```bash
flask run
```

If everything is installed correctly, and our virtual environment is activated, our terminal should display the following output:

<Img src="https://iili.io/HiQEXBn.png" alt="The output of our terminal, indicating that the backend is running well" />

Great! Now, let's begin testing our backend! In this tutorial, I'm going to use [Insomnia](https://insomnia.rest/), a free REST API testing and documentation design tool. It's straightforward to get started - simply create a new collection and begin adding the endpoints we need to test!

#### `/chat` endpoint

Let's test our `/chat` endpoint first! This endpoint accepts a JSON payload with a `messages` field, which is a list of message objects each containing `role` and `content` fields. Let's ask our backend this question: "let's talk about how we can innovate the health care system".

<Img src="https://iili.io/HiQEN2f.png" alt="We asked the backend to talk about how we can innovate the health care system" />

The backend should respond with its ideas about innovation in the health care system. Because we've specified in the backend code that we need our brainstorming partner to provide concise suggestions, it keeps the response short while still packing in essential information.

Next, how do we generate the speech from the backend? Remember the other endpoint besides `/chat`? That's right, we're going to use the `/talk` endpoint to incorporate speech generation into our brainstorming partner app.

#### `/talk` endpoint

Next, let's test our `/talk` endpoint. This endpoint accepts JSON as a parameter with a `message` field, where we input our message as a "script" that the ElevenLabs API will use to generate speech. For this test, we'll copy the response from the `/chat` endpoint earlier and use it as the payload for our request to the `/talk` endpoint.

<Img src="https://iili.io/HiQEh1s.png" alt="We made a request to the `/talk` endpoint and, after a while, we received an audio file containing the generated speech" />

After a few seconds, our `/talk` endpoint should return an audio file that we can play directly to test the result. Listen to the soothing voice of "Bella" as it reads the suggestion from the Claude model on how we should innovate the health care system. Impressive, isn't it? Now, what could make this even better? Of course, an app based on our backend that automatically plays the generated speech as the bot responds with its brainstorming suggestions.

### Building the Frontend

The frontend of our application will be a ReactJS application. We will create a chat interface where users can send messages and receive responses. When a user sends a message, a POST request will be sent to our Flask backend. The response, an audio file, will be played automatically. We will use the `useState` and `useEffect` hooks to manage state and side effects, and the Fetch API to send requests to our backend.

#### App.tsx

Here's the content of the `App.tsx` file:

```jsx
import React from 'react';
import logo from './logo.svg';
import './App.css';
import Chatbot from './components/Chatbot';

function App() {
  return (
    <div>
      <Chatbot />
    </div>
  );
}

export default App;
```

This is the main component of your React application. Let's break it down:

1. **Import necessary modules and components:**

```jsx
import React from 'react';
import logo from './logo.svg';
import './App.css';
import Chatbot from './components/Chatbot';
```

This section imports the necessary modules and components. `React` is the main library. `logo` is the logo of your application, `App.css` is the CSS file for styling your application, and `Chatbot` is the chatbot component that you will create.

2. **Define the App component:**

```jsx
function App() {
  return (
    <div>
      <Chatbot />
    </div>
  );
}
```

This is the definition of the `App` component. It's a functional component that returns a JSX element. The JSX returned by the component is a `div` that contains the `Chatbot` component. This means that the `Chatbot` component will be rendered inside this `div`.

3. **Export the App component:**

```jsx
export default App;
```

This line exports the `App` component as the default export of this module. This means that when this file is imported from another file, the `App` component will be the default import.

In the next sections, you will create the `Chatbot` component and add more functionality to your frontend application.

#### Chatbot.tsx

1. **Import necessary modules and hooks:**

```jsx
import React, { useState, useEffect, useRef } from 'react';
```

This line imports the `React` library and the `useState`, `useEffect`, and `useRef` hooks from React. `useState` is used to declare state variables, `useEffect` is used to perform side effects (like fetching data), and `useRef` is used to access DOM elements directly.

2. **Define the Message interface:**

```jsx
interface Message {
    role: string;
    content: string;
}
```

This TypeScript interface defines the shape of a `Message` object, which has a `role` and `content` property, both of which are strings.

3. **Define the Chatbot component:**

```jsx
const Chatbot: React.FC = () => {
    // ...
};
```

This line defines the `Chatbot` component as a functional component. The `React.FC` type annotation means that this component is a function component.

4. **Declare state variables and refs:**

```jsx
const [messages, setMessages] = useState<Message[]>([]);
const [input, setInput] = useState<string>('');
const [isLoading, setIsLoading] = useState<boolean>(false);
const audioRef = useRef<HTMLAudioElement>(null);
```

These lines declare state variables using the `useState` hook and a ref using the `useRef` hook. `messages` is an array of `Message` objects, `input` is a string, and `isLoading` is a boolean. `audioRef` is a ref to an `HTMLAudioElement`.

5. **Define event handlers:**

```jsx
const handleInputChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    setInput(event.target.value);
};

const handleSendMessage = async () => {
        setIsLoading(true);
        const newMessages = [...messages, { role: 'human', content: input }];

        // Send the user's message to the /chat endpoint
        const chatResponse = await fetch('http://localhost:5000/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ messages: newMessages }),
        });

        // Get the bot's response from the /chat endpoint
        const botResponse = await chatResponse.json();

        // Send the bot's response to the /talk endpoint
        const talkResponse = await fetch('http://localhost:5000/talk', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: botResponse.result }),
        });

        const audioBlob = await talkResponse.blob();

        let reader = new FileReader();
        reader.onload = () => {
            if (audioRef.current) {
                audioRef.current.src = reader.result as string;
                audioRef.current.play();
            }
        };
        reader.readAsDataURL(audioBlob);

        newMessages.push({ role: 'assistant', content: botResponse.result });
        setMessages(newMessages);
        setInput('');
        setIsLoading(false);
};
```

These functions are event handlers for the input change event and the send message button click event. `handleInputChange` updates the `input` state variable with the current value of the input field. `handleSendMessage` sends a POST request to the `/chat` and `/talk` endpoints, updates the `messages` state variable, and plays the received audio.

6. **Render the component:**

```jsx
return (
    <div className="flex flex-col items-center justify-center min-h-screen bg-gray-100">
            <p className='text-2xl text-blue-600 font-bold'>Brainstormy</p>
            <div className="flex flex-col w-full max-w-md p-4 bg-white rounded shadow">
                <div className="overflow-y-auto mb-4 max-h-60">
                    {messages.map((message, index) => (
                        <div key={index} className={`mb-4 ${message.role === 'assistant' ? 'text-blue-500' : 'text-green-500'}`}>
                            <strong>{message.role === 'assistant' ? 'Brainstormy' : 'User'}:</strong> {message.content}
                        </div>
                    ))}
                    {isLoading && <div className="p-4 bg-gray-200 animate-pulse">Thinking...</div>}
                </div>
                <div className="flex">
                    <input className="w-full px-4 py-2 mr-4 text-gray-700 bg-gray-200 rounded" value={input} onChange={handleInputChange} />
                    <button className="px-4 py-2 text-white bg-blue-500 rounded" onClick={handleSendMessage}>Send</button>
                </div>
                <audio ref={audioRef} controls className="w-full mt-4" />
            </div>
    </div>
);
```

This is the JSX that the `Chatbot` component returns. It's a `div` that contains all the elements of the chat interface, including the input field, send button, and audio player.

7. **Export the Chatbot component:**

```jsx
export default Chatbot;
```

This line exports the `Chatbot` component as the default export of this module. This means that when this file is imported from another file, the `Chatbot` component will be the default import.

#### public/index.html

Finally, to complete the visual of our brainstorming partner app, let's change the title of our app into "Brainstormy".

```diff
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="Web site created using create-react-app"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
--    <title>React App</title>
++     <title>Brainstormy</title>
  </head>
```

### Testing the Brainstormy App

Once our frontend is complete, it's time to test the entire application. We will interact with the chatbot, sending various messages and checking the responses. The responses should be relevant to our messages, and we should hear the synthesized speech of Claude's responses. If everything is working correctly, we have successfully built a chatbot application using the ElevenLabs API, Anthropic's Claude, ReactJS, and Flask.

To begin, let's run our front-end by executing this command:

```bash
npm start
```

Our browser should automatically open the app. At this point, it might look simple, but it has all the components that we need. It includes a component to display the chat history, a text input, and an audio player to play the generated speech from the backend.

<Img src="https://iili.io/HiQEVLX.png" alt="The view of our Brainstormy app, it has a title, text input, and an audio player" />

Let's ask our app to brainstorm some ideas on how we can innovate the health care system. After we're done, click the "Send" button!

<Img src="https://iili.io/HiQEjrG.png" alt="The app shows a loading indicator with the label 'Thinking'" />

Look how our Brainstormy app is thinking! Hopefully, it won't take long for the answer to arrive. 

<Img src="https://iili.io/HiQEO74.png" alt="The app shows the response and plays the generated speech immediately after it's received by the frontend" />

See? Just as in our real brainstorming sessions, we throw around ideas and let our mind focus on the topics at hand. It might take a while before the next person speaks up. However, once the response, along with the generated speech, is received, it's immediately played! So, we don't have to worry about missing anything by, for instance, leaving the window minimized, as we shall soon hear the Brainstormy app "speak" its mind.

## Conclusion

In this tutorial, we demonstrated how to use the ElevenLabs API to integrate AI-generated voice into our AI-powered brainstorming partner app. By leveraging Anthropic's Claude model, we ensured more engaging and human-like responses for our ideas, making it an ideal solution for a brainstorming partner app.

By delivering the generated voice as an audio file, we were able to seamlessly incorporate the voice into our front-end app, which automatically plays the audio response upon receipt. This feature enhances the interactivity of our brainstorming partner app, fostering more engaging discussions.

Thank you for joining me on this project, where we combined both text and voice to build an interactive chatbot app with a twist. I hope this tutorial has inspired you to brainstorm more with the app, or even sparked new ideas about how to utilize ElevenLabs in various use cases! You can find the projects for the [backend](https://github.com/septiannugraha/brainstormy-backend.git) and [frontend](https://github.com/septiannugraha/brainstormy-client.git) on my Github. Stay tuned for more exciting tutorials in the future!